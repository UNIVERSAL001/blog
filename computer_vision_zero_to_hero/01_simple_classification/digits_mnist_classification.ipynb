{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43dc3783-c3a9-4272-b962-84ece023858c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/homebrew/lib/python3.11/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchvision in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (0.16.0)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torchvision) (1.26.0)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.1.0 in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torchvision) (2.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torchvision) (10.0.1)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torch==2.1.0->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/homebrew/lib/python3.11/site-packages (from torch==2.1.0->torchvision) (4.7.1)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torch==2.1.0->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torch==2.1.0->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torch==2.1.0->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torch==2.1.0->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from requests->torchvision) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/opt/python-certifi/lib/python3.11/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from jinja2->torch==2.1.0->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "%pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93ec5420-1786-4213-b597-437311330845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0f4b904-787a-425a-bd80-382dd4557a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1f5adb0-204c-4f9d-ab5b-a9e6791af281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f8ccf8c-4e08-49fa-906e-7ca7dd00a7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_image(image, label):\n",
    "    plt.imshow(image.squeeze(), cmap='gray')\n",
    "    plt.title(f'Label: {label}')\n",
    "    plt.show()\n",
    "show_image(X[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eec40e39-eb95-47a0-81bf-f1605b754a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8806e99a-aec7-4d8a-ae53-bd34829ab47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d33d89a-021c-4313-bbe9-4e28385d00fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0014,  0.0336,  0.0182,  ..., -0.0318, -0.0343, -0.0282],\n",
       "         [-0.0036, -0.0323, -0.0093,  ..., -0.0015, -0.0115, -0.0050],\n",
       "         [ 0.0131,  0.0263, -0.0080,  ...,  0.0056, -0.0090,  0.0225],\n",
       "         ...,\n",
       "         [ 0.0236,  0.0344,  0.0041,  ...,  0.0132, -0.0329, -0.0338],\n",
       "         [ 0.0320,  0.0177, -0.0015,  ..., -0.0104, -0.0307, -0.0196],\n",
       "         [-0.0234, -0.0330, -0.0115,  ...,  0.0228, -0.0003, -0.0114]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-1.3600e-02,  1.1864e-02,  5.4885e-03, -1.6902e-02,  1.9671e-02,\n",
       "          4.2862e-03,  3.2405e-02, -5.9072e-03, -2.6209e-02, -4.5827e-03,\n",
       "          2.7865e-02,  2.9302e-02, -1.1871e-02,  3.3054e-02, -1.0095e-02,\n",
       "         -6.4868e-03, -3.0558e-02, -1.2347e-02,  1.2729e-02, -2.5318e-03,\n",
       "         -3.1488e-02, -3.5054e-02, -1.1316e-02,  1.0828e-02,  3.6050e-02,\n",
       "          2.4025e-02,  2.1746e-02, -4.0943e-03, -1.0703e-02,  2.7580e-03,\n",
       "         -1.7887e-02,  5.5075e-03, -1.8614e-03,  1.3560e-02, -2.6440e-02,\n",
       "         -2.9757e-02,  1.7428e-02, -1.9501e-02,  1.4025e-02, -3.5899e-02,\n",
       "         -3.5851e-02,  3.3643e-02, -2.1437e-03, -1.9066e-02,  2.4526e-02,\n",
       "         -1.5083e-02, -1.3303e-02,  3.2708e-02,  3.1936e-03, -2.1037e-02,\n",
       "          2.7266e-02,  8.5347e-03, -7.7533e-03, -3.8195e-04,  1.6570e-02,\n",
       "         -6.2814e-03, -1.4754e-02,  2.9256e-02,  7.6702e-03, -1.3216e-02,\n",
       "          2.0200e-02, -1.9098e-02, -1.1860e-02,  6.2700e-03, -3.0611e-02,\n",
       "         -1.1755e-02,  3.4668e-03,  3.4853e-02, -2.4359e-02,  3.2482e-02,\n",
       "          6.4121e-03, -1.2797e-02, -2.1779e-02,  1.0237e-02,  3.3362e-02,\n",
       "          1.8019e-02,  1.7739e-02, -2.5053e-02, -3.6357e-02,  4.3575e-03,\n",
       "         -7.1440e-03,  2.3892e-02, -1.5653e-02,  4.7164e-03,  8.3054e-03,\n",
       "         -3.5644e-03,  2.5092e-02, -2.6382e-02, -2.8969e-02,  8.9959e-03,\n",
       "         -2.1673e-02, -2.2639e-02, -2.1699e-02,  1.2738e-02, -2.6781e-02,\n",
       "          1.1845e-02, -1.2915e-02, -2.7489e-02,  2.4067e-02, -3.2282e-02,\n",
       "         -8.8770e-03,  1.0577e-02,  1.3838e-02,  7.2491e-03,  1.0659e-02,\n",
       "          1.8556e-02, -2.4131e-02,  2.0594e-02,  7.7821e-03, -1.0379e-02,\n",
       "         -6.4533e-03, -1.8988e-02, -6.8958e-03,  2.8985e-02,  3.2956e-02,\n",
       "          1.1770e-02,  3.0485e-02,  2.7807e-02,  1.3668e-02,  2.4930e-04,\n",
       "         -3.3515e-04,  1.9448e-02, -2.5565e-02,  2.7823e-02, -5.2478e-03,\n",
       "         -2.2889e-02, -3.1898e-02,  2.2231e-02, -1.3971e-02, -3.4817e-02,\n",
       "         -1.3137e-02,  2.8472e-02, -1.5942e-02,  6.0178e-03, -1.1723e-02,\n",
       "          1.9786e-02,  9.7004e-03, -6.9212e-04,  3.0072e-02, -1.5224e-02,\n",
       "         -1.1068e-02, -1.5344e-02, -3.0198e-02,  1.9627e-02,  3.5744e-02,\n",
       "          4.4690e-03,  1.4346e-02,  1.6861e-02,  1.8190e-02,  2.2055e-02,\n",
       "         -7.8610e-03, -3.6352e-03,  3.3665e-02,  8.8633e-03, -1.8927e-02,\n",
       "          5.5550e-03,  2.4741e-02,  1.5760e-02, -1.6285e-02,  3.4262e-02,\n",
       "         -1.0575e-02,  2.6406e-02,  1.6970e-02,  3.6266e-02, -5.1292e-03,\n",
       "         -1.2386e-02, -1.7767e-02, -2.3726e-02,  9.4211e-03, -1.0967e-02,\n",
       "          9.5258e-03,  3.2211e-02, -1.0159e-02,  1.9466e-02, -9.6745e-03,\n",
       "          1.1426e-02, -8.1487e-03, -2.4197e-02, -3.1893e-02, -1.1368e-02,\n",
       "          1.0213e-02,  2.6783e-03, -2.2384e-02, -2.1085e-02, -8.1345e-03,\n",
       "         -5.7233e-03,  1.7520e-02,  2.4888e-02, -2.7322e-02, -1.9004e-02,\n",
       "          8.8864e-03,  4.5982e-03,  1.2400e-02, -2.6794e-02,  5.7682e-03,\n",
       "         -2.5284e-02,  1.0734e-02,  4.9399e-03, -1.4496e-02, -1.9452e-02,\n",
       "          5.0442e-03,  2.1484e-02,  2.3902e-02,  5.0482e-03, -4.7306e-03,\n",
       "         -1.2550e-03, -3.6576e-02, -2.1430e-02, -3.1718e-02, -1.2581e-03,\n",
       "         -1.1379e-02,  2.0376e-02,  4.8901e-03,  2.7694e-02, -2.1006e-02,\n",
       "          2.2400e-04,  2.3523e-02, -2.5890e-02, -2.4921e-02,  1.6321e-02,\n",
       "         -3.0270e-02,  2.6814e-03,  3.1721e-02, -2.7184e-02, -2.5973e-02,\n",
       "          5.9913e-03, -2.8729e-02, -1.9810e-02, -1.2752e-02, -1.1564e-02,\n",
       "         -7.7345e-03, -1.0972e-02,  2.9508e-02,  2.7618e-02,  1.6333e-02,\n",
       "         -3.3526e-02,  1.4478e-02, -3.0653e-03, -2.3605e-02, -1.4678e-02,\n",
       "          1.3671e-02, -2.9783e-02, -1.6530e-02, -1.5985e-03, -2.5999e-03,\n",
       "         -1.9196e-02, -2.5685e-03, -3.8885e-03,  3.6081e-02,  1.9312e-04,\n",
       "         -2.3137e-02, -3.7339e-02, -1.4284e-02,  2.2271e-02, -4.6921e-03,\n",
       "         -2.1257e-02, -2.1291e-02, -3.3491e-02,  1.3319e-02, -1.9181e-02,\n",
       "         -2.2276e-02,  2.0869e-02, -3.3670e-02,  3.6487e-02,  2.3743e-02,\n",
       "         -3.0100e-02, -1.0961e-02, -2.9754e-02,  1.4469e-02,  1.0113e-03,\n",
       "         -2.9693e-02,  1.4921e-02, -1.8653e-02,  1.1148e-02, -6.0881e-03,\n",
       "         -3.3744e-02, -2.2221e-02, -3.1811e-02,  1.9149e-02, -2.5545e-03,\n",
       "         -6.3661e-03,  1.8637e-02, -1.6597e-02, -2.0890e-02,  4.3487e-03,\n",
       "          2.4083e-02, -3.0100e-02,  3.1535e-03,  3.4306e-03,  9.2395e-03,\n",
       "          1.3743e-02, -2.8308e-02,  1.9017e-02,  2.6087e-02,  5.0832e-03,\n",
       "          1.9447e-02, -9.0727e-03,  9.2526e-03,  8.5551e-03, -4.5949e-03,\n",
       "          3.5032e-02,  2.6538e-02,  6.3680e-03, -2.9049e-02, -2.8959e-02,\n",
       "         -1.9018e-02,  2.1649e-02, -3.5088e-02, -6.4664e-05,  4.2228e-03,\n",
       "         -5.5869e-03, -2.7719e-02,  1.2366e-02,  2.8106e-02,  2.4462e-03,\n",
       "          7.7370e-03,  3.5203e-03,  1.0137e-02, -8.1432e-03, -1.5889e-02,\n",
       "         -1.2898e-02, -3.5757e-04, -7.2244e-03, -1.7796e-02,  3.1477e-03,\n",
       "          1.5668e-02, -3.0369e-02, -1.4231e-02, -1.9590e-02,  1.4482e-02,\n",
       "          8.5233e-03, -7.1653e-03,  1.3378e-02, -1.6627e-02, -2.7152e-02,\n",
       "         -1.1075e-02,  1.3139e-02,  5.8483e-03, -2.3174e-02,  5.7620e-03,\n",
       "         -2.9450e-02, -1.0903e-02, -2.9674e-02,  1.4208e-02, -2.1493e-02,\n",
       "         -3.0305e-02, -3.8490e-03,  1.5687e-02,  2.7483e-02, -1.7805e-03,\n",
       "         -6.0862e-03, -2.1761e-02, -3.2870e-02, -3.6753e-02, -2.1214e-02,\n",
       "         -3.6335e-02,  2.3763e-02,  8.7037e-03,  4.7443e-03,  2.8493e-02,\n",
       "         -2.7061e-02,  1.5762e-02,  3.2455e-02, -2.6433e-02, -1.5985e-02,\n",
       "          2.2850e-02,  2.0159e-02, -2.4603e-04,  2.2625e-02,  2.8777e-02,\n",
       "         -3.3774e-02,  3.0306e-02,  2.1648e-03, -2.1763e-02,  2.0477e-02,\n",
       "         -3.1714e-02, -2.7525e-02,  1.6571e-02,  9.2319e-03,  7.0422e-03,\n",
       "         -1.8808e-02,  7.9990e-04,  1.7611e-02,  2.9165e-02,  7.9448e-04,\n",
       "          1.9895e-02,  2.1445e-02,  3.9107e-03,  1.4373e-02,  2.4143e-03,\n",
       "         -3.6056e-02, -2.2576e-02, -2.6962e-02,  3.4346e-02, -1.8275e-02,\n",
       "          5.1472e-03,  2.4775e-02, -8.7407e-03, -1.6247e-02,  2.3916e-02,\n",
       "         -2.6585e-03, -1.4650e-02, -3.5003e-02, -2.2553e-02, -2.1245e-02,\n",
       "          3.2255e-03, -6.4083e-03,  4.4087e-03, -1.1280e-02, -3.0442e-02,\n",
       "          5.1339e-03, -3.0603e-02,  5.5901e-03, -2.9530e-02,  7.8132e-03,\n",
       "          2.2291e-02,  1.7627e-02, -1.2190e-02, -2.1556e-02,  3.1110e-02,\n",
       "          2.2334e-02, -1.6496e-02,  1.1647e-02,  1.5485e-02, -3.1684e-02,\n",
       "          3.3088e-02,  1.6195e-03,  1.1712e-03,  1.6656e-03, -3.2677e-02,\n",
       "         -3.1182e-02,  2.3973e-02, -9.5490e-03,  3.4834e-03, -1.0560e-02,\n",
       "          1.3858e-03, -9.6659e-03,  5.3562e-03,  1.0059e-02, -3.0989e-03,\n",
       "          2.5728e-02,  1.8654e-02,  1.3627e-02, -9.4305e-03,  3.3082e-02,\n",
       "         -2.3054e-02,  2.2146e-02, -5.7493e-03,  2.6550e-02,  9.0188e-03,\n",
       "          2.4134e-02, -2.8561e-02, -1.4880e-02, -2.8133e-02, -1.9707e-02,\n",
       "         -9.5229e-03, -2.1568e-02,  1.8126e-03, -6.4801e-03, -9.2844e-05,\n",
       "         -7.9950e-03,  3.5007e-02,  1.5521e-02, -2.1049e-02,  1.7642e-02,\n",
       "          5.9406e-03,  1.1054e-02,  2.1347e-02, -6.0850e-03, -1.0291e-02,\n",
       "          2.1531e-02,  2.9177e-02,  2.7358e-02, -8.2946e-03, -1.1843e-02,\n",
       "          3.1660e-02, -2.6358e-02,  2.0955e-02, -2.9671e-02,  1.2460e-02,\n",
       "          8.8282e-03,  2.2581e-02, -1.5206e-02,  3.2443e-02, -3.6255e-02,\n",
       "          3.3745e-04, -2.3247e-02,  4.0790e-03, -1.3678e-02,  1.4718e-03,\n",
       "          2.4055e-02, -1.5680e-02, -1.7128e-02, -5.4629e-04, -1.7097e-03,\n",
       "          3.5139e-02, -1.0082e-02,  4.5717e-03, -7.6390e-03, -3.3026e-02,\n",
       "          3.5663e-02,  3.0746e-02, -2.1438e-02,  1.7206e-02, -3.0938e-02,\n",
       "         -1.3006e-02, -3.0668e-02,  1.5019e-02,  1.0234e-02,  2.3387e-02,\n",
       "          2.9348e-02,  4.2611e-04], requires_grad=True)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.linear_relu_stack[0].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "727c4c59-65fd-4539-a3bf-421827cb2897",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5124dd01-987a-46ff-8de5-7c8921f5ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b194b8c5-e795-40f3-8a04-ef5f5a915b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "717f9820-bb13-4dc6-8373-0a6d346ee869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 11.9%, Avg loss: 2.315746 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.320072  [   64/60000]\n",
      "loss: 2.281309  [ 6464/60000]\n",
      "loss: 2.270785  [12864/60000]\n",
      "loss: 2.220879  [19264/60000]\n",
      "loss: 2.213635  [25664/60000]\n",
      "loss: 2.202037  [32064/60000]\n",
      "loss: 2.129568  [38464/60000]\n",
      "loss: 2.146335  [44864/60000]\n",
      "loss: 2.097662  [51264/60000]\n",
      "loss: 2.075108  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.7%, Avg loss: 2.051794 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.059916  [   64/60000]\n",
      "loss: 2.008694  [ 6464/60000]\n",
      "loss: 2.020241  [12864/60000]\n",
      "loss: 1.905036  [19264/60000]\n",
      "loss: 1.925415  [25664/60000]\n",
      "loss: 1.910556  [32064/60000]\n",
      "loss: 1.800620  [38464/60000]\n",
      "loss: 1.871886  [44864/60000]\n",
      "loss: 1.773053  [51264/60000]\n",
      "loss: 1.727718  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 1.698042 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.718040  [   64/60000]\n",
      "loss: 1.630872  [ 6464/60000]\n",
      "loss: 1.664411  [12864/60000]\n",
      "loss: 1.499201  [19264/60000]\n",
      "loss: 1.524873  [25664/60000]\n",
      "loss: 1.503511  [32064/60000]\n",
      "loss: 1.374756  [38464/60000]\n",
      "loss: 1.506106  [44864/60000]\n",
      "loss: 1.383151  [51264/60000]\n",
      "loss: 1.321513  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 1.283851 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.324238  [   64/60000]\n",
      "loss: 1.211452  [ 6464/60000]\n",
      "loss: 1.271265  [12864/60000]\n",
      "loss: 1.116692  [19264/60000]\n",
      "loss: 1.126974  [25664/60000]\n",
      "loss: 1.117098  [32064/60000]\n",
      "loss: 1.015542  [38464/60000]\n",
      "loss: 1.180133  [44864/60000]\n",
      "loss: 1.078986  [51264/60000]\n",
      "loss: 1.023408  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.976671 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.038096  [   64/60000]\n",
      "loss: 0.917698  [ 6464/60000]\n",
      "loss: 0.981325  [12864/60000]\n",
      "loss: 0.875240  [19264/60000]\n",
      "loss: 0.867240  [25664/60000]\n",
      "loss: 0.860575  [32064/60000]\n",
      "loss: 0.789301  [38464/60000]\n",
      "loss: 0.954533  [44864/60000]\n",
      "loss: 0.889059  [51264/60000]\n",
      "loss: 0.847700  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.790373 \n",
      "\n",
      "Done in  15.751431226730347  seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "epochs = 5\n",
    "test(test_dataloader, model, loss_fn)\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done in \", time.time() - start, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "befb384d-b1ec-45b1-a549-c4309a7eb3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4013, -2.2614, -1.6052, -0.1392,  0.8867, -0.1384, -2.3127,  4.3744,\n",
       "         -0.4752,  2.1780]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(X[0].to(device))\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22b0bb76-6987-40ca-b8c7-5858badf45dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1698, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(preds[0].to(device), y[0].to(device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
