{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43dc3783-c3a9-4272-b962-84ece023858c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/homebrew/lib/python3.11/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchvision in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (0.16.0)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torchvision) (1.26.0)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.1.0 in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torchvision) (2.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torchvision) (10.0.1)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torch==2.1.0->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/homebrew/lib/python3.11/site-packages (from torch==2.1.0->torchvision) (4.7.1)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torch==2.1.0->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torch==2.1.0->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torch==2.1.0->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from torch==2.1.0->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from requests->torchvision) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/opt/python-certifi/lib/python3.11/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from jinja2->torch==2.1.0->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/lib/python3.11/site-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/Cellar/jupyterlab/4.0.6/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "%pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93ec5420-1786-4213-b597-437311330845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "torch.set_printoptions(sci_mode=False, precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0f4b904-787a-425a-bd80-382dd4557a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1f5adb0-204c-4f9d-ab5b-a9e6791af281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f0f5fe9-a95a-483f-88e7-4400478fbb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdbf50c8-40fe-4ffe-bec7-ade8159ea133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n"
     ]
    }
   ],
   "source": [
    "x = X[0].squeeze()\n",
    "for row in x:\n",
    "    for item in row:\n",
    "        pixel = 0\n",
    "        if item.item() > 0:\n",
    "            pixel = 1\n",
    "        print(pixel, end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f8ccf8c-4e08-49fa-906e-7ca7dd00a7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_image(image, label):\n",
    "    plt.imshow(image.squeeze(), cmap='gray')\n",
    "    plt.title(f'Label: {label}')\n",
    "    plt.show()\n",
    "show_image(X[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eec40e39-eb95-47a0-81bf-f1605b754a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8806e99a-aec7-4d8a-ae53-bd34829ab47e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "727c4c59-65fd-4539-a3bf-421827cb2897",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95516488-21d1-49c4-97a3-aae342a709df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0098, -0.0101, -0.0528, -0.0755, -0.0253,  0.0151,  0.0595,  0.0199,\n",
      "          0.0427,  0.0480]], device='mps:0', grad_fn=<LinearBackward0>) torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "x = X[:1].to(device)\n",
    "pred = model(x)\n",
    "print(pred, pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4bf530d-ba3a-45c7-bb9e-1c5cd7509088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0988, 0.0988, 0.0947, 0.0925, 0.0973, 0.1013, 0.1059, 0.1018, 0.1042,\n",
       "         0.1047]], device='mps:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Softmax(dim=1)(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47de2a97-1d6b-4006-8f54-b07781ec7756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8b4f202-2241-47fc-b994-8d2258cd9b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1018, device='mps:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Softmax(dim=1)(pred)[0][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf5dd72a-e2f5-4200-88ea-10c5fe59fe16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.284745174865715"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log\n",
    "-log(0.1018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c21c62b1-e8d0-4f1c-998a-863bd1ac82e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2848, device='mps:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(pred, y[:1].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5124dd01-987a-46ff-8de5-7c8921f5ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b194b8c5-e795-40f3-8a04-ef5f5a915b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "717f9820-bb13-4dc6-8373-0a6d346ee869",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 9.9%, Avg loss: 2.305079 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.305354  [   64/60000]\n",
      "loss: 2.306510  [ 6464/60000]\n",
      "loss: 2.295852  [12864/60000]\n",
      "loss: 2.295866  [19264/60000]\n",
      "loss: 2.290308  [25664/60000]\n",
      "loss: 2.285594  [32064/60000]\n",
      "loss: 2.271096  [38464/60000]\n",
      "loss: 2.269572  [44864/60000]\n",
      "loss: 2.274406  [51264/60000]\n",
      "loss: 2.261976  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 41.3%, Avg loss: 2.261502 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.260743  [   64/60000]\n",
      "loss: 2.257151  [ 6464/60000]\n",
      "loss: 2.258801  [12864/60000]\n",
      "loss: 2.238646  [19264/60000]\n",
      "loss: 2.243764  [25664/60000]\n",
      "loss: 2.237744  [32064/60000]\n",
      "loss: 2.214426  [38464/60000]\n",
      "loss: 2.227140  [44864/60000]\n",
      "loss: 2.216366  [51264/60000]\n",
      "loss: 2.198596  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.8%, Avg loss: 2.200028 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.198215  [   64/60000]\n",
      "loss: 2.185686  [ 6464/60000]\n",
      "loss: 2.203362  [12864/60000]\n",
      "loss: 2.153223  [19264/60000]\n",
      "loss: 2.171935  [25664/60000]\n",
      "loss: 2.161814  [32064/60000]\n",
      "loss: 2.121442  [38464/60000]\n",
      "loss: 2.152217  [44864/60000]\n",
      "loss: 2.119874  [51264/60000]\n",
      "loss: 2.091871  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 2.094993 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.091644  [   64/60000]\n",
      "loss: 2.062621  [ 6464/60000]\n",
      "loss: 2.107361  [12864/60000]\n",
      "loss: 2.007070  [19264/60000]\n",
      "loss: 2.046148  [25664/60000]\n",
      "loss: 2.026682  [32064/60000]\n",
      "loss: 1.958762  [38464/60000]\n",
      "loss: 2.017316  [44864/60000]\n",
      "loss: 1.953549  [51264/60000]\n",
      "loss: 1.908935  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.6%, Avg loss: 1.912757 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.912127  [   64/60000]\n",
      "loss: 1.855702  [ 6464/60000]\n",
      "loss: 1.935011  [12864/60000]\n",
      "loss: 1.772415  [19264/60000]\n",
      "loss: 1.825444  [25664/60000]\n",
      "loss: 1.793133  [32064/60000]\n",
      "loss: 1.701386  [38464/60000]\n",
      "loss: 1.797795  [44864/60000]\n",
      "loss: 1.693938  [51264/60000]\n",
      "loss: 1.632501  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 1.631034 \n",
      "\n",
      "Done in  20.46895694732666  seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "epochs = 5\n",
    "test(test_dataloader, model, loss_fn)\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done in \", time.time() - start, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72ac81cd-b7c1-4011-9053-ab369f802162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 1.631034 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.647415  [   64/60000]\n",
      "loss: 1.549637  [ 6464/60000]\n",
      "loss: 1.661005  [12864/60000]\n",
      "loss: 1.457065  [19264/60000]\n",
      "loss: 1.502079  [25664/60000]\n",
      "loss: 1.463558  [32064/60000]\n",
      "loss: 1.373312  [38464/60000]\n",
      "loss: 1.509465  [44864/60000]\n",
      "loss: 1.382244  [51264/60000]\n",
      "loss: 1.311181  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 1.301543 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.346093  [   64/60000]\n",
      "loss: 1.213548  [ 6464/60000]\n",
      "loss: 1.340459  [12864/60000]\n",
      "loss: 1.150326  [19264/60000]\n",
      "loss: 1.174443  [25664/60000]\n",
      "loss: 1.137131  [32064/60000]\n",
      "loss: 1.068849  [38464/60000]\n",
      "loss: 1.232008  [44864/60000]\n",
      "loss: 1.119539  [51264/60000]\n",
      "loss: 1.044258  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 1.031163 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.100121  [   64/60000]\n",
      "loss: 0.954179  [ 6464/60000]\n",
      "loss: 1.075944  [12864/60000]\n",
      "loss: 0.927328  [19264/60000]\n",
      "loss: 0.936953  [25664/60000]\n",
      "loss: 0.900013  [32064/60000]\n",
      "loss: 0.850417  [38464/60000]\n",
      "loss: 1.024397  [44864/60000]\n",
      "loss: 0.939135  [51264/60000]\n",
      "loss: 0.865688  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.848155 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.930625  [   64/60000]\n",
      "loss: 0.783018  [ 6464/60000]\n",
      "loss: 0.891907  [12864/60000]\n",
      "loss: 0.780440  [19264/60000]\n",
      "loss: 0.782234  [25664/60000]\n",
      "loss: 0.745245  [32064/60000]\n",
      "loss: 0.703648  [38464/60000]\n",
      "loss: 0.881093  [44864/60000]\n",
      "loss: 0.818148  [51264/60000]\n",
      "loss: 0.751674  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.726752 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.814601  [   64/60000]\n",
      "loss: 0.668786  [ 6464/60000]\n",
      "loss: 0.765072  [12864/60000]\n",
      "loss: 0.683167  [19264/60000]\n",
      "loss: 0.678070  [25664/60000]\n",
      "loss: 0.643876  [32064/60000]\n",
      "loss: 0.602169  [38464/60000]\n",
      "loss: 0.781836  [44864/60000]\n",
      "loss: 0.733250  [51264/60000]\n",
      "loss: 0.677091  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.643242 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.731810  [   64/60000]\n",
      "loss: 0.588530  [ 6464/60000]\n",
      "loss: 0.674742  [12864/60000]\n",
      "loss: 0.616759  [19264/60000]\n",
      "loss: 0.604040  [25664/60000]\n",
      "loss: 0.575587  [32064/60000]\n",
      "loss: 0.529258  [38464/60000]\n",
      "loss: 0.711394  [44864/60000]\n",
      "loss: 0.670745  [51264/60000]\n",
      "loss: 0.626281  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.583264 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.669983  [   64/60000]\n",
      "loss: 0.529416  [ 6464/60000]\n",
      "loss: 0.607808  [12864/60000]\n",
      "loss: 0.569577  [19264/60000]\n",
      "loss: 0.548813  [25664/60000]\n",
      "loss: 0.528037  [32064/60000]\n",
      "loss: 0.475058  [38464/60000]\n",
      "loss: 0.659853  [44864/60000]\n",
      "loss: 0.622778  [51264/60000]\n",
      "loss: 0.590270  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.538433 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.621697  [   64/60000]\n",
      "loss: 0.484186  [ 6464/60000]\n",
      "loss: 0.556474  [12864/60000]\n",
      "loss: 0.534605  [19264/60000]\n",
      "loss: 0.505993  [25664/60000]\n",
      "loss: 0.493767  [32064/60000]\n",
      "loss: 0.433570  [38464/60000]\n",
      "loss: 0.620915  [44864/60000]\n",
      "loss: 0.584837  [51264/60000]\n",
      "loss: 0.563909  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.503750 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.582663  [   64/60000]\n",
      "loss: 0.448605  [ 6464/60000]\n",
      "loss: 0.515767  [12864/60000]\n",
      "loss: 0.507787  [19264/60000]\n",
      "loss: 0.471797  [25664/60000]\n",
      "loss: 0.468280  [32064/60000]\n",
      "loss: 0.400948  [38464/60000]\n",
      "loss: 0.590613  [44864/60000]\n",
      "loss: 0.554120  [51264/60000]\n",
      "loss: 0.543871  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.476145 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.550235  [   64/60000]\n",
      "loss: 0.420083  [ 6464/60000]\n",
      "loss: 0.482482  [12864/60000]\n",
      "loss: 0.486492  [19264/60000]\n",
      "loss: 0.443873  [25664/60000]\n",
      "loss: 0.448768  [32064/60000]\n",
      "loss: 0.374705  [38464/60000]\n",
      "loss: 0.566252  [44864/60000]\n",
      "loss: 0.528727  [51264/60000]\n",
      "loss: 0.528221  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.453665 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.522660  [   64/60000]\n",
      "loss: 0.396879  [ 6464/60000]\n",
      "loss: 0.454541  [12864/60000]\n",
      "loss: 0.469071  [19264/60000]\n",
      "loss: 0.420586  [25664/60000]\n",
      "loss: 0.433307  [32064/60000]\n",
      "loss: 0.353140  [38464/60000]\n",
      "loss: 0.546060  [44864/60000]\n",
      "loss: 0.507362  [51264/60000]\n",
      "loss: 0.515801  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.435018 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.498780  [   64/60000]\n",
      "loss: 0.377742  [ 6464/60000]\n",
      "loss: 0.430560  [12864/60000]\n",
      "loss: 0.454582  [19264/60000]\n",
      "loss: 0.400843  [25664/60000]\n",
      "loss: 0.420736  [32064/60000]\n",
      "loss: 0.335122  [38464/60000]\n",
      "loss: 0.529034  [44864/60000]\n",
      "loss: 0.489229  [51264/60000]\n",
      "loss: 0.505735  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.419316 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.477832  [   64/60000]\n",
      "loss: 0.361774  [ 6464/60000]\n",
      "loss: 0.409742  [12864/60000]\n",
      "loss: 0.442321  [19264/60000]\n",
      "loss: 0.383907  [25664/60000]\n",
      "loss: 0.410282  [32064/60000]\n",
      "loss: 0.319864  [38464/60000]\n",
      "loss: 0.514414  [44864/60000]\n",
      "loss: 0.473619  [51264/60000]\n",
      "loss: 0.497470  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.405922 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.459205  [   64/60000]\n",
      "loss: 0.348368  [ 6464/60000]\n",
      "loss: 0.391378  [12864/60000]\n",
      "loss: 0.431818  [19264/60000]\n",
      "loss: 0.369213  [25664/60000]\n",
      "loss: 0.401400  [32064/60000]\n",
      "loss: 0.306766  [38464/60000]\n",
      "loss: 0.501645  [44864/60000]\n",
      "loss: 0.459977  [51264/60000]\n",
      "loss: 0.490552  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.394367 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.442463  [   64/60000]\n",
      "loss: 0.337013  [ 6464/60000]\n",
      "loss: 0.375003  [12864/60000]\n",
      "loss: 0.422733  [19264/60000]\n",
      "loss: 0.356317  [25664/60000]\n",
      "loss: 0.393703  [32064/60000]\n",
      "loss: 0.295377  [38464/60000]\n",
      "loss: 0.490357  [44864/60000]\n",
      "loss: 0.447908  [51264/60000]\n",
      "loss: 0.484678  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.384294 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.427290  [   64/60000]\n",
      "loss: 0.327350  [ 6464/60000]\n",
      "loss: 0.360260  [12864/60000]\n",
      "loss: 0.414804  [19264/60000]\n",
      "loss: 0.344945  [25664/60000]\n",
      "loss: 0.386932  [32064/60000]\n",
      "loss: 0.285402  [38464/60000]\n",
      "loss: 0.480277  [44864/60000]\n",
      "loss: 0.437178  [51264/60000]\n",
      "loss: 0.479604  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.375427 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.413433  [   64/60000]\n",
      "loss: 0.319105  [ 6464/60000]\n",
      "loss: 0.346907  [12864/60000]\n",
      "loss: 0.407752  [19264/60000]\n",
      "loss: 0.334844  [25664/60000]\n",
      "loss: 0.380863  [32064/60000]\n",
      "loss: 0.276605  [38464/60000]\n",
      "loss: 0.471198  [44864/60000]\n",
      "loss: 0.427545  [51264/60000]\n",
      "loss: 0.475170  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.367547 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.400789  [   64/60000]\n",
      "loss: 0.312029  [ 6464/60000]\n",
      "loss: 0.334709  [12864/60000]\n",
      "loss: 0.401412  [19264/60000]\n",
      "loss: 0.325753  [25664/60000]\n",
      "loss: 0.375376  [32064/60000]\n",
      "loss: 0.268775  [38464/60000]\n",
      "loss: 0.462970  [44864/60000]\n",
      "loss: 0.418832  [51264/60000]\n",
      "loss: 0.471196  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.360489 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.389083  [   64/60000]\n",
      "loss: 0.305927  [ 6464/60000]\n",
      "loss: 0.323516  [12864/60000]\n",
      "loss: 0.395725  [19264/60000]\n",
      "loss: 0.317545  [25664/60000]\n",
      "loss: 0.370348  [32064/60000]\n",
      "loss: 0.261746  [38464/60000]\n",
      "loss: 0.455462  [44864/60000]\n",
      "loss: 0.410900  [51264/60000]\n",
      "loss: 0.467591  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.354117 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.378209  [   64/60000]\n",
      "loss: 0.300608  [ 6464/60000]\n",
      "loss: 0.313218  [12864/60000]\n",
      "loss: 0.390588  [19264/60000]\n",
      "loss: 0.310100  [25664/60000]\n",
      "loss: 0.365683  [32064/60000]\n",
      "loss: 0.255400  [38464/60000]\n",
      "loss: 0.448610  [44864/60000]\n",
      "loss: 0.403584  [51264/60000]\n",
      "loss: 0.464275  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.348319 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.368075  [   64/60000]\n",
      "loss: 0.295954  [ 6464/60000]\n",
      "loss: 0.303719  [12864/60000]\n",
      "loss: 0.385873  [19264/60000]\n",
      "loss: 0.303274  [25664/60000]\n",
      "loss: 0.361327  [32064/60000]\n",
      "loss: 0.249655  [38464/60000]\n",
      "loss: 0.442293  [44864/60000]\n",
      "loss: 0.396793  [51264/60000]\n",
      "loss: 0.461135  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.4%, Avg loss: 0.343011 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.358588  [   64/60000]\n",
      "loss: 0.291871  [ 6464/60000]\n",
      "loss: 0.294942  [12864/60000]\n",
      "loss: 0.381554  [19264/60000]\n",
      "loss: 0.297021  [25664/60000]\n",
      "loss: 0.357233  [32064/60000]\n",
      "loss: 0.244453  [38464/60000]\n",
      "loss: 0.436475  [44864/60000]\n",
      "loss: 0.390417  [51264/60000]\n",
      "loss: 0.458160  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.338118 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.349681  [   64/60000]\n",
      "loss: 0.288261  [ 6464/60000]\n",
      "loss: 0.286786  [12864/60000]\n",
      "loss: 0.377604  [19264/60000]\n",
      "loss: 0.291278  [25664/60000]\n",
      "loss: 0.353353  [32064/60000]\n",
      "loss: 0.239716  [38464/60000]\n",
      "loss: 0.431110  [44864/60000]\n",
      "loss: 0.384364  [51264/60000]\n",
      "loss: 0.455325  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.333583 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.341243  [   64/60000]\n",
      "loss: 0.285064  [ 6464/60000]\n",
      "loss: 0.279203  [12864/60000]\n",
      "loss: 0.373943  [19264/60000]\n",
      "loss: 0.285957  [25664/60000]\n",
      "loss: 0.349720  [32064/60000]\n",
      "loss: 0.235365  [38464/60000]\n",
      "loss: 0.426111  [44864/60000]\n",
      "loss: 0.378586  [51264/60000]\n",
      "loss: 0.452563  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.6%, Avg loss: 0.329357 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.333256  [   64/60000]\n",
      "loss: 0.282213  [ 6464/60000]\n",
      "loss: 0.272155  [12864/60000]\n",
      "loss: 0.370502  [19264/60000]\n",
      "loss: 0.281011  [25664/60000]\n",
      "loss: 0.346286  [32064/60000]\n",
      "loss: 0.231351  [38464/60000]\n",
      "loss: 0.421499  [44864/60000]\n",
      "loss: 0.373067  [51264/60000]\n",
      "loss: 0.449963  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.325397 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.325657  [   64/60000]\n",
      "loss: 0.279623  [ 6464/60000]\n",
      "loss: 0.265558  [12864/60000]\n",
      "loss: 0.367219  [19264/60000]\n",
      "loss: 0.276396  [25664/60000]\n",
      "loss: 0.343024  [32064/60000]\n",
      "loss: 0.227634  [38464/60000]\n",
      "loss: 0.417214  [44864/60000]\n",
      "loss: 0.367734  [51264/60000]\n",
      "loss: 0.447424  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.321669 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.318447  [   64/60000]\n",
      "loss: 0.277270  [ 6464/60000]\n",
      "loss: 0.259390  [12864/60000]\n",
      "loss: 0.364223  [19264/60000]\n",
      "loss: 0.272075  [25664/60000]\n",
      "loss: 0.339913  [32064/60000]\n",
      "loss: 0.224180  [38464/60000]\n",
      "loss: 0.413224  [44864/60000]\n",
      "loss: 0.362637  [51264/60000]\n",
      "loss: 0.444985  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.318149 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.311554  [   64/60000]\n",
      "loss: 0.275087  [ 6464/60000]\n",
      "loss: 0.253630  [12864/60000]\n",
      "loss: 0.361423  [19264/60000]\n",
      "loss: 0.268054  [25664/60000]\n",
      "loss: 0.336875  [32064/60000]\n",
      "loss: 0.220892  [38464/60000]\n",
      "loss: 0.409505  [44864/60000]\n",
      "loss: 0.357707  [51264/60000]\n",
      "loss: 0.442607  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.314814 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.305003  [   64/60000]\n",
      "loss: 0.273063  [ 6464/60000]\n",
      "loss: 0.248267  [12864/60000]\n",
      "loss: 0.358766  [19264/60000]\n",
      "loss: 0.264243  [25664/60000]\n",
      "loss: 0.333976  [32064/60000]\n",
      "loss: 0.217807  [38464/60000]\n",
      "loss: 0.406013  [44864/60000]\n",
      "loss: 0.352920  [51264/60000]\n",
      "loss: 0.440266  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.311637 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.298734  [   64/60000]\n",
      "loss: 0.271177  [ 6464/60000]\n",
      "loss: 0.243236  [12864/60000]\n",
      "loss: 0.356248  [19264/60000]\n",
      "loss: 0.260612  [25664/60000]\n",
      "loss: 0.331188  [32064/60000]\n",
      "loss: 0.214884  [38464/60000]\n",
      "loss: 0.402733  [44864/60000]\n",
      "loss: 0.348276  [51264/60000]\n",
      "loss: 0.437945  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.308609 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.292713  [   64/60000]\n",
      "loss: 0.269402  [ 6464/60000]\n",
      "loss: 0.238502  [12864/60000]\n",
      "loss: 0.353853  [19264/60000]\n",
      "loss: 0.257137  [25664/60000]\n",
      "loss: 0.328524  [32064/60000]\n",
      "loss: 0.212113  [38464/60000]\n",
      "loss: 0.399626  [44864/60000]\n",
      "loss: 0.343770  [51264/60000]\n",
      "loss: 0.435607  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.305710 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.286924  [   64/60000]\n",
      "loss: 0.267704  [ 6464/60000]\n",
      "loss: 0.234025  [12864/60000]\n",
      "loss: 0.351484  [19264/60000]\n",
      "loss: 0.253819  [25664/60000]\n",
      "loss: 0.325960  [32064/60000]\n",
      "loss: 0.209478  [38464/60000]\n",
      "loss: 0.396629  [44864/60000]\n",
      "loss: 0.339437  [51264/60000]\n",
      "loss: 0.433252  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.302934 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.281381  [   64/60000]\n",
      "loss: 0.266040  [ 6464/60000]\n",
      "loss: 0.229786  [12864/60000]\n",
      "loss: 0.349222  [19264/60000]\n",
      "loss: 0.250649  [25664/60000]\n",
      "loss: 0.323451  [32064/60000]\n",
      "loss: 0.207035  [38464/60000]\n",
      "loss: 0.393788  [44864/60000]\n",
      "loss: 0.335217  [51264/60000]\n",
      "loss: 0.431007  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.300267 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.276019  [   64/60000]\n",
      "loss: 0.264468  [ 6464/60000]\n",
      "loss: 0.225748  [12864/60000]\n",
      "loss: 0.347036  [19264/60000]\n",
      "loss: 0.247592  [25664/60000]\n",
      "loss: 0.321027  [32064/60000]\n",
      "loss: 0.204719  [38464/60000]\n",
      "loss: 0.391087  [44864/60000]\n",
      "loss: 0.331072  [51264/60000]\n",
      "loss: 0.428764  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.297696 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.270864  [   64/60000]\n",
      "loss: 0.262943  [ 6464/60000]\n",
      "loss: 0.221903  [12864/60000]\n",
      "loss: 0.344936  [19264/60000]\n",
      "loss: 0.244613  [25664/60000]\n",
      "loss: 0.318713  [32064/60000]\n",
      "loss: 0.202505  [38464/60000]\n",
      "loss: 0.388504  [44864/60000]\n",
      "loss: 0.327070  [51264/60000]\n",
      "loss: 0.426577  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.295211 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.265909  [   64/60000]\n",
      "loss: 0.261456  [ 6464/60000]\n",
      "loss: 0.218230  [12864/60000]\n",
      "loss: 0.342900  [19264/60000]\n",
      "loss: 0.241770  [25664/60000]\n",
      "loss: 0.316441  [32064/60000]\n",
      "loss: 0.200409  [38464/60000]\n",
      "loss: 0.386048  [44864/60000]\n",
      "loss: 0.323240  [51264/60000]\n",
      "loss: 0.424367  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.292808 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.261119  [   64/60000]\n",
      "loss: 0.260011  [ 6464/60000]\n",
      "loss: 0.214741  [12864/60000]\n",
      "loss: 0.340937  [19264/60000]\n",
      "loss: 0.239034  [25664/60000]\n",
      "loss: 0.314265  [32064/60000]\n",
      "loss: 0.198390  [38464/60000]\n",
      "loss: 0.383665  [44864/60000]\n",
      "loss: 0.319487  [51264/60000]\n",
      "loss: 0.422161  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.290474 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.256487  [   64/60000]\n",
      "loss: 0.258612  [ 6464/60000]\n",
      "loss: 0.211385  [12864/60000]\n",
      "loss: 0.338965  [19264/60000]\n",
      "loss: 0.236443  [25664/60000]\n",
      "loss: 0.312170  [32064/60000]\n",
      "loss: 0.196435  [38464/60000]\n",
      "loss: 0.381387  [44864/60000]\n",
      "loss: 0.315811  [51264/60000]\n",
      "loss: 0.419943  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.288208 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.252019  [   64/60000]\n",
      "loss: 0.257228  [ 6464/60000]\n",
      "loss: 0.208178  [12864/60000]\n",
      "loss: 0.337000  [19264/60000]\n",
      "loss: 0.233979  [25664/60000]\n",
      "loss: 0.310158  [32064/60000]\n",
      "loss: 0.194552  [38464/60000]\n",
      "loss: 0.379191  [44864/60000]\n",
      "loss: 0.312254  [51264/60000]\n",
      "loss: 0.417725  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.286001 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.247704  [   64/60000]\n",
      "loss: 0.255809  [ 6464/60000]\n",
      "loss: 0.205125  [12864/60000]\n",
      "loss: 0.335051  [19264/60000]\n",
      "loss: 0.231622  [25664/60000]\n",
      "loss: 0.308193  [32064/60000]\n",
      "loss: 0.192702  [38464/60000]\n",
      "loss: 0.377109  [44864/60000]\n",
      "loss: 0.308763  [51264/60000]\n",
      "loss: 0.415533  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.283852 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.243527  [   64/60000]\n",
      "loss: 0.254401  [ 6464/60000]\n",
      "loss: 0.202212  [12864/60000]\n",
      "loss: 0.333138  [19264/60000]\n",
      "loss: 0.229340  [25664/60000]\n",
      "loss: 0.306304  [32064/60000]\n",
      "loss: 0.190931  [38464/60000]\n",
      "loss: 0.375095  [44864/60000]\n",
      "loss: 0.305311  [51264/60000]\n",
      "loss: 0.413345  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.281761 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.239463  [   64/60000]\n",
      "loss: 0.252971  [ 6464/60000]\n",
      "loss: 0.199428  [12864/60000]\n",
      "loss: 0.331264  [19264/60000]\n",
      "loss: 0.227146  [25664/60000]\n",
      "loss: 0.304459  [32064/60000]\n",
      "loss: 0.189221  [38464/60000]\n",
      "loss: 0.373088  [44864/60000]\n",
      "loss: 0.301970  [51264/60000]\n",
      "loss: 0.411147  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.279714 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.235526  [   64/60000]\n",
      "loss: 0.251528  [ 6464/60000]\n",
      "loss: 0.196758  [12864/60000]\n",
      "loss: 0.329485  [19264/60000]\n",
      "loss: 0.224995  [25664/60000]\n",
      "loss: 0.302651  [32064/60000]\n",
      "loss: 0.187559  [38464/60000]\n",
      "loss: 0.371118  [44864/60000]\n",
      "loss: 0.298713  [51264/60000]\n",
      "loss: 0.408954  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.277710 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.231704  [   64/60000]\n",
      "loss: 0.250106  [ 6464/60000]\n",
      "loss: 0.194176  [12864/60000]\n",
      "loss: 0.327744  [19264/60000]\n",
      "loss: 0.222913  [25664/60000]\n",
      "loss: 0.300826  [32064/60000]\n",
      "loss: 0.185937  [38464/60000]\n",
      "loss: 0.369253  [44864/60000]\n",
      "loss: 0.295530  [51264/60000]\n",
      "loss: 0.406697  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.275751 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.227972  [   64/60000]\n",
      "loss: 0.248744  [ 6464/60000]\n",
      "loss: 0.191702  [12864/60000]\n",
      "loss: 0.326020  [19264/60000]\n",
      "loss: 0.220916  [25664/60000]\n",
      "loss: 0.299060  [32064/60000]\n",
      "loss: 0.184389  [38464/60000]\n",
      "loss: 0.367431  [44864/60000]\n",
      "loss: 0.292402  [51264/60000]\n",
      "loss: 0.404448  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.273835 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.224298  [   64/60000]\n",
      "loss: 0.247404  [ 6464/60000]\n",
      "loss: 0.189320  [12864/60000]\n",
      "loss: 0.324286  [19264/60000]\n",
      "loss: 0.219014  [25664/60000]\n",
      "loss: 0.297337  [32064/60000]\n",
      "loss: 0.182844  [38464/60000]\n",
      "loss: 0.365639  [44864/60000]\n",
      "loss: 0.289309  [51264/60000]\n",
      "loss: 0.402210  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.271954 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.220742  [   64/60000]\n",
      "loss: 0.246094  [ 6464/60000]\n",
      "loss: 0.187031  [12864/60000]\n",
      "loss: 0.322568  [19264/60000]\n",
      "loss: 0.217220  [25664/60000]\n",
      "loss: 0.295654  [32064/60000]\n",
      "loss: 0.181347  [38464/60000]\n",
      "loss: 0.363817  [44864/60000]\n",
      "loss: 0.286279  [51264/60000]\n",
      "loss: 0.400009  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.270110 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.217252  [   64/60000]\n",
      "loss: 0.244816  [ 6464/60000]\n",
      "loss: 0.184811  [12864/60000]\n",
      "loss: 0.320858  [19264/60000]\n",
      "loss: 0.215394  [25664/60000]\n",
      "loss: 0.294017  [32064/60000]\n",
      "loss: 0.179843  [38464/60000]\n",
      "loss: 0.361987  [44864/60000]\n",
      "loss: 0.283299  [51264/60000]\n",
      "loss: 0.397819  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.268299 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.213852  [   64/60000]\n",
      "loss: 0.243506  [ 6464/60000]\n",
      "loss: 0.182663  [12864/60000]\n",
      "loss: 0.319177  [19264/60000]\n",
      "loss: 0.213609  [25664/60000]\n",
      "loss: 0.292430  [32064/60000]\n",
      "loss: 0.178326  [38464/60000]\n",
      "loss: 0.360162  [44864/60000]\n",
      "loss: 0.280320  [51264/60000]\n",
      "loss: 0.395609  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.266512 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.210586  [   64/60000]\n",
      "loss: 0.242216  [ 6464/60000]\n",
      "loss: 0.180568  [12864/60000]\n",
      "loss: 0.317523  [19264/60000]\n",
      "loss: 0.211872  [25664/60000]\n",
      "loss: 0.290833  [32064/60000]\n",
      "loss: 0.176854  [38464/60000]\n",
      "loss: 0.358330  [44864/60000]\n",
      "loss: 0.277356  [51264/60000]\n",
      "loss: 0.393387  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.264758 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.207403  [   64/60000]\n",
      "loss: 0.240948  [ 6464/60000]\n",
      "loss: 0.178527  [12864/60000]\n",
      "loss: 0.315923  [19264/60000]\n",
      "loss: 0.210186  [25664/60000]\n",
      "loss: 0.289229  [32064/60000]\n",
      "loss: 0.175421  [38464/60000]\n",
      "loss: 0.356514  [44864/60000]\n",
      "loss: 0.274419  [51264/60000]\n",
      "loss: 0.391195  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.263029 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.204319  [   64/60000]\n",
      "loss: 0.239707  [ 6464/60000]\n",
      "loss: 0.176565  [12864/60000]\n",
      "loss: 0.314311  [19264/60000]\n",
      "loss: 0.208518  [25664/60000]\n",
      "loss: 0.287676  [32064/60000]\n",
      "loss: 0.173996  [38464/60000]\n",
      "loss: 0.354718  [44864/60000]\n",
      "loss: 0.271509  [51264/60000]\n",
      "loss: 0.389033  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.261327 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.201336  [   64/60000]\n",
      "loss: 0.238466  [ 6464/60000]\n",
      "loss: 0.174696  [12864/60000]\n",
      "loss: 0.312692  [19264/60000]\n",
      "loss: 0.206920  [25664/60000]\n",
      "loss: 0.286107  [32064/60000]\n",
      "loss: 0.172595  [38464/60000]\n",
      "loss: 0.352931  [44864/60000]\n",
      "loss: 0.268634  [51264/60000]\n",
      "loss: 0.386893  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.259651 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.198434  [   64/60000]\n",
      "loss: 0.237273  [ 6464/60000]\n",
      "loss: 0.172881  [12864/60000]\n",
      "loss: 0.311045  [19264/60000]\n",
      "loss: 0.205331  [25664/60000]\n",
      "loss: 0.284568  [32064/60000]\n",
      "loss: 0.171220  [38464/60000]\n",
      "loss: 0.351145  [44864/60000]\n",
      "loss: 0.265832  [51264/60000]\n",
      "loss: 0.384723  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.257996 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.195616  [   64/60000]\n",
      "loss: 0.236076  [ 6464/60000]\n",
      "loss: 0.171138  [12864/60000]\n",
      "loss: 0.309440  [19264/60000]\n",
      "loss: 0.203801  [25664/60000]\n",
      "loss: 0.283098  [32064/60000]\n",
      "loss: 0.169851  [38464/60000]\n",
      "loss: 0.349375  [44864/60000]\n",
      "loss: 0.263061  [51264/60000]\n",
      "loss: 0.382544  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.256361 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.192873  [   64/60000]\n",
      "loss: 0.234923  [ 6464/60000]\n",
      "loss: 0.169467  [12864/60000]\n",
      "loss: 0.307845  [19264/60000]\n",
      "loss: 0.202324  [25664/60000]\n",
      "loss: 0.281605  [32064/60000]\n",
      "loss: 0.168459  [38464/60000]\n",
      "loss: 0.347613  [44864/60000]\n",
      "loss: 0.260354  [51264/60000]\n",
      "loss: 0.380336  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.254745 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.190202  [   64/60000]\n",
      "loss: 0.233800  [ 6464/60000]\n",
      "loss: 0.167803  [12864/60000]\n",
      "loss: 0.306230  [19264/60000]\n",
      "loss: 0.200867  [25664/60000]\n",
      "loss: 0.280139  [32064/60000]\n",
      "loss: 0.167083  [38464/60000]\n",
      "loss: 0.345844  [44864/60000]\n",
      "loss: 0.257654  [51264/60000]\n",
      "loss: 0.378156  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.253139 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.187588  [   64/60000]\n",
      "loss: 0.232690  [ 6464/60000]\n",
      "loss: 0.166143  [12864/60000]\n",
      "loss: 0.304662  [19264/60000]\n",
      "loss: 0.199439  [25664/60000]\n",
      "loss: 0.278746  [32064/60000]\n",
      "loss: 0.165734  [38464/60000]\n",
      "loss: 0.344099  [44864/60000]\n",
      "loss: 0.254967  [51264/60000]\n",
      "loss: 0.376007  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.8%, Avg loss: 0.251554 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.185057  [   64/60000]\n",
      "loss: 0.231559  [ 6464/60000]\n",
      "loss: 0.164546  [12864/60000]\n",
      "loss: 0.303068  [19264/60000]\n",
      "loss: 0.198041  [25664/60000]\n",
      "loss: 0.277400  [32064/60000]\n",
      "loss: 0.164401  [38464/60000]\n",
      "loss: 0.342361  [44864/60000]\n",
      "loss: 0.252268  [51264/60000]\n",
      "loss: 0.373873  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.8%, Avg loss: 0.249987 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.182560  [   64/60000]\n",
      "loss: 0.230380  [ 6464/60000]\n",
      "loss: 0.162988  [12864/60000]\n",
      "loss: 0.301508  [19264/60000]\n",
      "loss: 0.196670  [25664/60000]\n",
      "loss: 0.276146  [32064/60000]\n",
      "loss: 0.163082  [38464/60000]\n",
      "loss: 0.340673  [44864/60000]\n",
      "loss: 0.249620  [51264/60000]\n",
      "loss: 0.371740  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.9%, Avg loss: 0.248441 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.180141  [   64/60000]\n",
      "loss: 0.229174  [ 6464/60000]\n",
      "loss: 0.161462  [12864/60000]\n",
      "loss: 0.299955  [19264/60000]\n",
      "loss: 0.195344  [25664/60000]\n",
      "loss: 0.274926  [32064/60000]\n",
      "loss: 0.161798  [38464/60000]\n",
      "loss: 0.339010  [44864/60000]\n",
      "loss: 0.247009  [51264/60000]\n",
      "loss: 0.369551  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.246910 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.177794  [   64/60000]\n",
      "loss: 0.227973  [ 6464/60000]\n",
      "loss: 0.159967  [12864/60000]\n",
      "loss: 0.298406  [19264/60000]\n",
      "loss: 0.194035  [25664/60000]\n",
      "loss: 0.273769  [32064/60000]\n",
      "loss: 0.160520  [38464/60000]\n",
      "loss: 0.337306  [44864/60000]\n",
      "loss: 0.244490  [51264/60000]\n",
      "loss: 0.367348  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.245390 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.175516  [   64/60000]\n",
      "loss: 0.226753  [ 6464/60000]\n",
      "loss: 0.158531  [12864/60000]\n",
      "loss: 0.296823  [19264/60000]\n",
      "loss: 0.192735  [25664/60000]\n",
      "loss: 0.272650  [32064/60000]\n",
      "loss: 0.159238  [38464/60000]\n",
      "loss: 0.335634  [44864/60000]\n",
      "loss: 0.242001  [51264/60000]\n",
      "loss: 0.365098  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.243887 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.173279  [   64/60000]\n",
      "loss: 0.225517  [ 6464/60000]\n",
      "loss: 0.157107  [12864/60000]\n",
      "loss: 0.295238  [19264/60000]\n",
      "loss: 0.191431  [25664/60000]\n",
      "loss: 0.271535  [32064/60000]\n",
      "loss: 0.157980  [38464/60000]\n",
      "loss: 0.333982  [44864/60000]\n",
      "loss: 0.239563  [51264/60000]\n",
      "loss: 0.362889  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.1%, Avg loss: 0.242396 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.171105  [   64/60000]\n",
      "loss: 0.224246  [ 6464/60000]\n",
      "loss: 0.155761  [12864/60000]\n",
      "loss: 0.293665  [19264/60000]\n",
      "loss: 0.190136  [25664/60000]\n",
      "loss: 0.270432  [32064/60000]\n",
      "loss: 0.156715  [38464/60000]\n",
      "loss: 0.332313  [44864/60000]\n",
      "loss: 0.237129  [51264/60000]\n",
      "loss: 0.360697  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.1%, Avg loss: 0.240919 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.168977  [   64/60000]\n",
      "loss: 0.222958  [ 6464/60000]\n",
      "loss: 0.154450  [12864/60000]\n",
      "loss: 0.292112  [19264/60000]\n",
      "loss: 0.188846  [25664/60000]\n",
      "loss: 0.269316  [32064/60000]\n",
      "loss: 0.155456  [38464/60000]\n",
      "loss: 0.330662  [44864/60000]\n",
      "loss: 0.234724  [51264/60000]\n",
      "loss: 0.358518  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.239451 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.166893  [   64/60000]\n",
      "loss: 0.221697  [ 6464/60000]\n",
      "loss: 0.153170  [12864/60000]\n",
      "loss: 0.290533  [19264/60000]\n",
      "loss: 0.187585  [25664/60000]\n",
      "loss: 0.268215  [32064/60000]\n",
      "loss: 0.154206  [38464/60000]\n",
      "loss: 0.329026  [44864/60000]\n",
      "loss: 0.232318  [51264/60000]\n",
      "loss: 0.356361  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.237996 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.164871  [   64/60000]\n",
      "loss: 0.220455  [ 6464/60000]\n",
      "loss: 0.151901  [12864/60000]\n",
      "loss: 0.288972  [19264/60000]\n",
      "loss: 0.186339  [25664/60000]\n",
      "loss: 0.267135  [32064/60000]\n",
      "loss: 0.152972  [38464/60000]\n",
      "loss: 0.327430  [44864/60000]\n",
      "loss: 0.229973  [51264/60000]\n",
      "loss: 0.354232  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.236549 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.162878  [   64/60000]\n",
      "loss: 0.219220  [ 6464/60000]\n",
      "loss: 0.150659  [12864/60000]\n",
      "loss: 0.287425  [19264/60000]\n",
      "loss: 0.185062  [25664/60000]\n",
      "loss: 0.266030  [32064/60000]\n",
      "loss: 0.151738  [38464/60000]\n",
      "loss: 0.325775  [44864/60000]\n",
      "loss: 0.227622  [51264/60000]\n",
      "loss: 0.352130  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.235115 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.160932  [   64/60000]\n",
      "loss: 0.217937  [ 6464/60000]\n",
      "loss: 0.149445  [12864/60000]\n",
      "loss: 0.285908  [19264/60000]\n",
      "loss: 0.183778  [25664/60000]\n",
      "loss: 0.264934  [32064/60000]\n",
      "loss: 0.150516  [38464/60000]\n",
      "loss: 0.324093  [44864/60000]\n",
      "loss: 0.225330  [51264/60000]\n",
      "loss: 0.350037  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.233696 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.159024  [   64/60000]\n",
      "loss: 0.216636  [ 6464/60000]\n",
      "loss: 0.148250  [12864/60000]\n",
      "loss: 0.284418  [19264/60000]\n",
      "loss: 0.182510  [25664/60000]\n",
      "loss: 0.263867  [32064/60000]\n",
      "loss: 0.149315  [38464/60000]\n",
      "loss: 0.322439  [44864/60000]\n",
      "loss: 0.223060  [51264/60000]\n",
      "loss: 0.347942  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.232284 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.157149  [   64/60000]\n",
      "loss: 0.215359  [ 6464/60000]\n",
      "loss: 0.147049  [12864/60000]\n",
      "loss: 0.282916  [19264/60000]\n",
      "loss: 0.181255  [25664/60000]\n",
      "loss: 0.262853  [32064/60000]\n",
      "loss: 0.148107  [38464/60000]\n",
      "loss: 0.320799  [44864/60000]\n",
      "loss: 0.220807  [51264/60000]\n",
      "loss: 0.345914  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.230884 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.155317  [   64/60000]\n",
      "loss: 0.214078  [ 6464/60000]\n",
      "loss: 0.145886  [12864/60000]\n",
      "loss: 0.281412  [19264/60000]\n",
      "loss: 0.180016  [25664/60000]\n",
      "loss: 0.261893  [32064/60000]\n",
      "loss: 0.146913  [38464/60000]\n",
      "loss: 0.319169  [44864/60000]\n",
      "loss: 0.218582  [51264/60000]\n",
      "loss: 0.343936  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.229494 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.153529  [   64/60000]\n",
      "loss: 0.212821  [ 6464/60000]\n",
      "loss: 0.144745  [12864/60000]\n",
      "loss: 0.279905  [19264/60000]\n",
      "loss: 0.178778  [25664/60000]\n",
      "loss: 0.260954  [32064/60000]\n",
      "loss: 0.145728  [38464/60000]\n",
      "loss: 0.317535  [44864/60000]\n",
      "loss: 0.216372  [51264/60000]\n",
      "loss: 0.342027  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.228116 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.151775  [   64/60000]\n",
      "loss: 0.211591  [ 6464/60000]\n",
      "loss: 0.143622  [12864/60000]\n",
      "loss: 0.278417  [19264/60000]\n",
      "loss: 0.177551  [25664/60000]\n",
      "loss: 0.260063  [32064/60000]\n",
      "loss: 0.144538  [38464/60000]\n",
      "loss: 0.315946  [44864/60000]\n",
      "loss: 0.214200  [51264/60000]\n",
      "loss: 0.340133  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.6%, Avg loss: 0.226748 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.150035  [   64/60000]\n",
      "loss: 0.210398  [ 6464/60000]\n",
      "loss: 0.142506  [12864/60000]\n",
      "loss: 0.276921  [19264/60000]\n",
      "loss: 0.176336  [25664/60000]\n",
      "loss: 0.259246  [32064/60000]\n",
      "loss: 0.143347  [38464/60000]\n",
      "loss: 0.314356  [44864/60000]\n",
      "loss: 0.212061  [51264/60000]\n",
      "loss: 0.338243  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.6%, Avg loss: 0.225389 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.148337  [   64/60000]\n",
      "loss: 0.209211  [ 6464/60000]\n",
      "loss: 0.141395  [12864/60000]\n",
      "loss: 0.275406  [19264/60000]\n",
      "loss: 0.175117  [25664/60000]\n",
      "loss: 0.258431  [32064/60000]\n",
      "loss: 0.142175  [38464/60000]\n",
      "loss: 0.312750  [44864/60000]\n",
      "loss: 0.209959  [51264/60000]\n",
      "loss: 0.336377  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.7%, Avg loss: 0.224041 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.146683  [   64/60000]\n",
      "loss: 0.208036  [ 6464/60000]\n",
      "loss: 0.140307  [12864/60000]\n",
      "loss: 0.273915  [19264/60000]\n",
      "loss: 0.173919  [25664/60000]\n",
      "loss: 0.257593  [32064/60000]\n",
      "loss: 0.141021  [38464/60000]\n",
      "loss: 0.311139  [44864/60000]\n",
      "loss: 0.207882  [51264/60000]\n",
      "loss: 0.334521  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.7%, Avg loss: 0.222703 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.145065  [   64/60000]\n",
      "loss: 0.206900  [ 6464/60000]\n",
      "loss: 0.139220  [12864/60000]\n",
      "loss: 0.272339  [19264/60000]\n",
      "loss: 0.172707  [25664/60000]\n",
      "loss: 0.256755  [32064/60000]\n",
      "loss: 0.139840  [38464/60000]\n",
      "loss: 0.309511  [44864/60000]\n",
      "loss: 0.205846  [51264/60000]\n",
      "loss: 0.332621  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.221375 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.143463  [   64/60000]\n",
      "loss: 0.205770  [ 6464/60000]\n",
      "loss: 0.138141  [12864/60000]\n",
      "loss: 0.270770  [19264/60000]\n",
      "loss: 0.171508  [25664/60000]\n",
      "loss: 0.255914  [32064/60000]\n",
      "loss: 0.138640  [38464/60000]\n",
      "loss: 0.307904  [44864/60000]\n",
      "loss: 0.203872  [51264/60000]\n",
      "loss: 0.330718  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.220057 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.141881  [   64/60000]\n",
      "loss: 0.204654  [ 6464/60000]\n",
      "loss: 0.137079  [12864/60000]\n",
      "loss: 0.269211  [19264/60000]\n",
      "loss: 0.170334  [25664/60000]\n",
      "loss: 0.255078  [32064/60000]\n",
      "loss: 0.137463  [38464/60000]\n",
      "loss: 0.306280  [44864/60000]\n",
      "loss: 0.201948  [51264/60000]\n",
      "loss: 0.328843  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.218750 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.140327  [   64/60000]\n",
      "loss: 0.203600  [ 6464/60000]\n",
      "loss: 0.136037  [12864/60000]\n",
      "loss: 0.267614  [19264/60000]\n",
      "loss: 0.169159  [25664/60000]\n",
      "loss: 0.254224  [32064/60000]\n",
      "loss: 0.136318  [38464/60000]\n",
      "loss: 0.304611  [44864/60000]\n",
      "loss: 0.200079  [51264/60000]\n",
      "loss: 0.327032  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.217457 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.138824  [   64/60000]\n",
      "loss: 0.202561  [ 6464/60000]\n",
      "loss: 0.134984  [12864/60000]\n",
      "loss: 0.266040  [19264/60000]\n",
      "loss: 0.168022  [25664/60000]\n",
      "loss: 0.253365  [32064/60000]\n",
      "loss: 0.135196  [38464/60000]\n",
      "loss: 0.302921  [44864/60000]\n",
      "loss: 0.198246  [51264/60000]\n",
      "loss: 0.325254  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.216176 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.137353  [   64/60000]\n",
      "loss: 0.201565  [ 6464/60000]\n",
      "loss: 0.133984  [12864/60000]\n",
      "loss: 0.264522  [19264/60000]\n",
      "loss: 0.166910  [25664/60000]\n",
      "loss: 0.252476  [32064/60000]\n",
      "loss: 0.134071  [38464/60000]\n",
      "loss: 0.301247  [44864/60000]\n",
      "loss: 0.196464  [51264/60000]\n",
      "loss: 0.323518  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.214905 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.135931  [   64/60000]\n",
      "loss: 0.200595  [ 6464/60000]\n",
      "loss: 0.132985  [12864/60000]\n",
      "loss: 0.263012  [19264/60000]\n",
      "loss: 0.165809  [25664/60000]\n",
      "loss: 0.251583  [32064/60000]\n",
      "loss: 0.132964  [38464/60000]\n",
      "loss: 0.299579  [44864/60000]\n",
      "loss: 0.194750  [51264/60000]\n",
      "loss: 0.321759  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.213646 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.134560  [   64/60000]\n",
      "loss: 0.199636  [ 6464/60000]\n",
      "loss: 0.131991  [12864/60000]\n",
      "loss: 0.261488  [19264/60000]\n",
      "loss: 0.164719  [25664/60000]\n",
      "loss: 0.250704  [32064/60000]\n",
      "loss: 0.131869  [38464/60000]\n",
      "loss: 0.297915  [44864/60000]\n",
      "loss: 0.193093  [51264/60000]\n",
      "loss: 0.319995  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.212397 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.133221  [   64/60000]\n",
      "loss: 0.198673  [ 6464/60000]\n",
      "loss: 0.131015  [12864/60000]\n",
      "loss: 0.259970  [19264/60000]\n",
      "loss: 0.163640  [25664/60000]\n",
      "loss: 0.249838  [32064/60000]\n",
      "loss: 0.130786  [38464/60000]\n",
      "loss: 0.296251  [44864/60000]\n",
      "loss: 0.191454  [51264/60000]\n",
      "loss: 0.318262  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.211159 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.131894  [   64/60000]\n",
      "loss: 0.197733  [ 6464/60000]\n",
      "loss: 0.130050  [12864/60000]\n",
      "loss: 0.258464  [19264/60000]\n",
      "loss: 0.162589  [25664/60000]\n",
      "loss: 0.248963  [32064/60000]\n",
      "loss: 0.129729  [38464/60000]\n",
      "loss: 0.294612  [44864/60000]\n",
      "loss: 0.189871  [51264/60000]\n",
      "loss: 0.316559  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.209934 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.130568  [   64/60000]\n",
      "loss: 0.196826  [ 6464/60000]\n",
      "loss: 0.129071  [12864/60000]\n",
      "loss: 0.256982  [19264/60000]\n",
      "loss: 0.161550  [25664/60000]\n",
      "loss: 0.248121  [32064/60000]\n",
      "loss: 0.128685  [38464/60000]\n",
      "loss: 0.293020  [44864/60000]\n",
      "loss: 0.188326  [51264/60000]\n",
      "loss: 0.314878  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.208721 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.129263  [   64/60000]\n",
      "loss: 0.195937  [ 6464/60000]\n",
      "loss: 0.128134  [12864/60000]\n",
      "loss: 0.255511  [19264/60000]\n",
      "loss: 0.160507  [25664/60000]\n",
      "loss: 0.247272  [32064/60000]\n",
      "loss: 0.127654  [38464/60000]\n",
      "loss: 0.291439  [44864/60000]\n",
      "loss: 0.186812  [51264/60000]\n",
      "loss: 0.313222  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.207519 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.127976  [   64/60000]\n",
      "loss: 0.195025  [ 6464/60000]\n",
      "loss: 0.127223  [12864/60000]\n",
      "loss: 0.254055  [19264/60000]\n",
      "loss: 0.159462  [25664/60000]\n",
      "loss: 0.246421  [32064/60000]\n",
      "loss: 0.126612  [38464/60000]\n",
      "loss: 0.289878  [44864/60000]\n",
      "loss: 0.185332  [51264/60000]\n",
      "loss: 0.311583  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.206327 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.126704  [   64/60000]\n",
      "loss: 0.194112  [ 6464/60000]\n",
      "loss: 0.126331  [12864/60000]\n",
      "loss: 0.252654  [19264/60000]\n",
      "loss: 0.158433  [25664/60000]\n",
      "loss: 0.245557  [32064/60000]\n",
      "loss: 0.125587  [38464/60000]\n",
      "loss: 0.288344  [44864/60000]\n",
      "loss: 0.183872  [51264/60000]\n",
      "loss: 0.309968  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.205146 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.125470  [   64/60000]\n",
      "loss: 0.193191  [ 6464/60000]\n",
      "loss: 0.125450  [12864/60000]\n",
      "loss: 0.251231  [19264/60000]\n",
      "loss: 0.157412  [25664/60000]\n",
      "loss: 0.244703  [32064/60000]\n",
      "loss: 0.124545  [38464/60000]\n",
      "loss: 0.286860  [44864/60000]\n",
      "loss: 0.182433  [51264/60000]\n",
      "loss: 0.308363  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.203976 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.124275  [   64/60000]\n",
      "loss: 0.192278  [ 6464/60000]\n",
      "loss: 0.124586  [12864/60000]\n",
      "loss: 0.249838  [19264/60000]\n",
      "loss: 0.156385  [25664/60000]\n",
      "loss: 0.243859  [32064/60000]\n",
      "loss: 0.123497  [38464/60000]\n",
      "loss: 0.285381  [44864/60000]\n",
      "loss: 0.181063  [51264/60000]\n",
      "loss: 0.306800  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.202815 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.123114  [   64/60000]\n",
      "loss: 0.191374  [ 6464/60000]\n",
      "loss: 0.123738  [12864/60000]\n",
      "loss: 0.248473  [19264/60000]\n",
      "loss: 0.155376  [25664/60000]\n",
      "loss: 0.242983  [32064/60000]\n",
      "loss: 0.122463  [38464/60000]\n",
      "loss: 0.283924  [44864/60000]\n",
      "loss: 0.179754  [51264/60000]\n",
      "loss: 0.305273  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.201665 \n",
      "\n",
      "Done in  393.3018298149109  seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "epochs = 95\n",
    "test(test_dataloader, model, loss_fn)\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done in \", time.time() - start, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a7adcd-e451-4473-8dae-f5eacb7fdaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "epochs = 95\n",
    "test(test_dataloader, model, loss_fn)\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done in \", time.time() - start, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58bcf520-c74a-4fb5-b411-ea91773635c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6160, -5.7304,  2.7560,  4.3435, -4.2726,  0.4242, -9.5664,  9.8647,\n",
       "         -0.1756,  2.2468]], device='mps:0', grad_fn=<LinearBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(X[0].to(device))\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9faf34b-6cbc-4193-a789-4cf46c8c668b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "209c5586-ab98-4819-86a2-6c7396144a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0.0001,     0.0000,     0.0008,     0.0040,     0.0000,     0.0001,\n",
       "             0.0000,     0.9945,     0.0000,     0.0005]], device='mps:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Softmax(dim=1)(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73d83a18-dcfb-4065-9ba2-1c15934067b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0055, device='mps:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(preds, y[:1].to(device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
